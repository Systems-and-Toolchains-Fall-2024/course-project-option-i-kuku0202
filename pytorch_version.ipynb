{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\spark\\spark-3.5.3-bin-hadoop3\\python\\pyspark\\sql\\context.py:113: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "\n",
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext, SQLContext\n",
    "\n",
    "properties = {\n",
    "    'username': 'postgres',\n",
    "    'password': '20020202',\n",
    "    'url': \"jdbc:postgresql://localhost:5432/postgres\",\n",
    "    'table': 'fifa.player_data',\n",
    "    'driver': 'org.postgresql.Driver'\n",
    "}\n",
    "\n",
    "def write_to_pgadmin(df, mode='overwrite'):\n",
    "    df.write.format('jdbc').mode(mode)\\\n",
    "        .option(\"url\", properties['url'])\\\n",
    "        .option(\"dbtable\", properties['table'])\\\n",
    "        .option(\"user\", properties['username'])\\\n",
    "        .option(\"password\", properties['password'])\\\n",
    "        .option(\"Driver\", properties['driver'])\\\n",
    "        .save()\n",
    "\n",
    "def read_from_pgadmin():\n",
    "    return spark.read.format(\"jdbc\")\\\n",
    "        .option(\"url\", properties['url'])\\\n",
    "        .option(\"dbtable\", properties['table'])\\\n",
    "        .option(\"user\", properties['username'])\\\n",
    "        .option(\"password\", properties['password'])\\\n",
    "        .option(\"Driver\", properties['driver'])\\\n",
    "        .load()\n",
    "\n",
    "appName = \"Big Data Analytics\"\n",
    "master = \"local\"\n",
    "\n",
    "# Create Configuration object for Spark.\n",
    "conf = pyspark.SparkConf()\\\n",
    "    .set('spark.driver.host','127.0.0.1')\\\n",
    "    .set('spark.jars.packages', 'org.postgresql:postgresql:42.7.0')\\\n",
    "    .setAppName(appName)\\\n",
    "    .setMaster(master)\n",
    "\n",
    "# conf = pyspark.SparkConf().\\\n",
    "#     set('spark.jars.packages', 'org.postgresql:postgresql:42.7.0')\\\n",
    "#     .setAppName(appName).setMaster(master)\n",
    "\n",
    "# Create Spark Context with the new configurations rather than relying on the default one\n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "\n",
    "# You need to create SQL Context to conduct some database operations like what we will see later.\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "# If you have SQL context, you create the session from the Spark Context\n",
    "spark = sqlContext.sparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocess import *\n",
    "df = read_from_pgadmin()\n",
    "df_clean = clean_data(df)\n",
    "properties['table'] = 'fifa.clean_data'\n",
    "write_to_pgadmin(df_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+---------+---------+---------+-----------+------------------------+-------------+----------------+---------+----+--------+-------+---------+---------+------+------------------+-------------------+--------------------------+-----------------------+-----------------+---------------+-----------+-----------------+------------------+------------------+---------------------+---------------------+----------------+------------------+----------------+----------------+-------------+-------------+--------------+----------------+--------------------+-----------------------+---------------------+----------------+-------------------+---------------------------+-------------------------+------------------------+------------------+--------------------+-------------------+-----------------------+--------------------+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+-----------------+\n",
      "|overall|age|height_cm|weight_kg|weak_foot|skill_moves|international_reputation|    work_rate|       body_type|real_face|pace|shooting|passing|dribbling|defending|physic|attacking_crossing|attacking_finishing|attacking_heading_accuracy|attacking_short_passing|attacking_volleys|skill_dribbling|skill_curve|skill_fk_accuracy|skill_long_passing|skill_ball_control|movement_acceleration|movement_sprint_speed|movement_agility|movement_reactions|movement_balance|power_shot_power|power_jumping|power_stamina|power_strength|power_long_shots|mentality_aggression|mentality_interceptions|mentality_positioning|mentality_vision|mentality_penalties|defending_marking_awareness|defending_standing_tackle|defending_sliding_tackle|goalkeeping_diving|goalkeeping_handling|goalkeeping_kicking|goalkeeping_positioning|goalkeeping_reflexes|  ls|  st|  rs|  lw|  lf|  cf|  rf|  rw| lam| cam| ram|  lm| lcm|  cm| rcm|  rm| lwb| ldm| cdm| rdm| rwb|  lb| lcb|  cb| rcb|  rb|  gk|prefer_right_foot|\n",
      "+-------+---+---------+---------+---------+-----------+------------------------+-------------+----------------+---------+----+--------+-------+---------+---------+------+------------------+-------------------+--------------------------+-----------------------+-----------------+---------------+-----------+-----------------+------------------+------------------+---------------------+---------------------+----------------+------------------+----------------+----------------+-------------+-------------+--------------+----------------+--------------------+-----------------------+---------------------+----------------+-------------------+---------------------------+-------------------------+------------------------+------------------+--------------------+-------------------+-----------------------+--------------------+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+-----------------+\n",
      "|     94| 28|      170|       72|        4|          4|                       5|   Medium/Low|          Unique|      Yes|  92|      88|     86|       95|       24|    62|                80|                 93|                        71|                     88|               85|             96|         89|               90|                79|                96|                   95|                   90|              92|                92|              95|              80|           68|           76|            59|              88|                  48|                     22|                   90|              90|                 74|                         13|                       23|                      21|                 6|                  11|                 15|                     14|                   8|87.0|87.0|87.0|91.0|91.0|91.0|91.0|91.0|91.0|91.0|91.0|90.0|82.0|82.0|82.0|90.0|62.0|57.0|57.0|57.0|62.0|57.0|44.0|44.0|44.0|57.0|19.0|               No|\n",
      "|     93| 30|      185|       80|        4|          5|                       5|     High/Low|          Unique|      Yes|  92|      93|     80|       91|       33|    78|                82|                 95|                        86|                     81|               87|             93|         88|               77|                72|                91|                   91|                   93|              90|                92|              62|              94|           94|           87|            79|              93|                  62|                     29|                   93|              81|                 85|                         22|                       31|                      23|                 7|                  11|                 15|                     14|                  11|91.0|91.0|91.0|90.0|91.0|91.0|91.0|90.0|88.0|88.0|88.0|88.0|80.0|80.0|80.0|88.0|64.0|60.0|60.0|60.0|64.0|60.0|52.0|52.0|52.0|60.0|20.0|              Yes|\n",
      "|     90| 31|      180|       80|        2|          4|                       5|     High/Low|Normal (170-185)|      Yes|  92|      86|     82|       92|       32|    64|                80|                 85|                        51|                     85|               86|             93|         86|               83|                74|                90|                   92|                   92|              91|                91|              91|              86|           61|           76|            65|              90|                  47|                     39|                   89|              84|                 80|                         29|                       26|                      26|                10|                   8|                 11|                      5|                  15|84.0|84.0|84.0|89.0|88.0|88.0|88.0|89.0|88.0|88.0|88.0|87.0|80.0|80.0|80.0|87.0|65.0|60.0|60.0|60.0|65.0|59.0|47.0|47.0|47.0|59.0|19.0|               No|\n",
      "|     90| 29|      193|       92|        4|          1|                       5|Medium/Medium|   Normal (185+)|      Yes|  69|      54|     58|       63|       56|    66|                15|                 13|                        25|                     48|               11|             16|         14|               11|                47|                31|                   58|                   61|              43|                88|              35|              25|           78|           44|            83|              16|                  29|                     30|                   12|              70|                 37|                         10|                       10|                      11|                85|                  87|                 91|                     90|                  86|33.0|33.0|33.0|35.0|36.0|36.0|36.0|35.0|40.0|40.0|40.0|38.0|42.0|42.0|42.0|38.0|33.0|38.0|38.0|38.0|33.0|33.0|33.0|33.0|33.0|33.0|87.0|              Yes|\n",
      "|     90| 28|      182|       85|        4|          4|                       5|  High/Medium|Normal (170-185)|      Yes|  83|      88|     79|       87|       42|    79|                77|                 90|                        77|                     82|               87|             88|         86|               84|                64|                91|                   88|                   78|              86|                91|              60|              88|           69|           86|            76|              85|                  78|                     41|                   91|              84|                 85|                         30|                       45|                      38|                27|                  25|                 31|                     33|                  37|87.0|87.0|87.0|87.0|88.0|88.0|88.0|87.0|86.0|86.0|86.0|85.0|79.0|79.0|79.0|85.0|67.0|65.0|65.0|65.0|67.0|64.0|58.0|58.0|58.0|64.0|37.0|              Yes|\n",
      "+-------+---+---------+---------+---------+-----------+------------------------+-------------+----------------+---------+----+--------+-------+---------+---------+------+------------------+-------------------+--------------------------+-----------------------+-----------------+---------------+-----------+-----------------+------------------+------------------+---------------------+---------------------+----------------+------------------+----------------+----------------+-------------+-------------+--------------+----------------+--------------------+-----------------------+---------------------+----------------+-------------------+---------------------------+-------------------------+------------------------+------------------+--------------------+-------------------+-----------------------+--------------------+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+----+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from preprocess import *\n",
    "properties['table'] = 'fifa.clean_data'\n",
    "df_new = read_from_pgadmin()\n",
    "df_new.show(5)\n",
    "preprocess_pipeline = get_preprocess_pipeline()\n",
    "preprocess_pipeline_model = preprocess_pipeline.fit(df_new)\n",
    "df_processed = preprocess_pipeline_model.transform(df_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|outcome|            features|\n",
      "+-------+--------------------+\n",
      "|   94.0|[6.00629302994062...|\n",
      "|   93.0|[6.43531396065066...|\n",
      "|   90.0|[6.64982442600569...|\n",
      "|   90.0|[6.22080349529564...|\n",
      "|   90.0|[6.00629302994062...|\n",
      "+-------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_processed.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = df_processed.randomSplit([0.8, 0.2], seed=42)\n",
    "train_df, val_df = train_df.randomSplit([0.75, 0.25], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = np.array(train_df.select(\"features\").rdd.flatMap(lambda x: x).collect())\n",
    "y_train = np.array(train_df.select(\"outcome\").rdd.flatMap(lambda x: x).collect())\n",
    "\n",
    "X_val = np.array(val_df.select(\"features\").rdd.flatMap(lambda x: x).collect())\n",
    "y_val = np.array(val_df.select(\"outcome\").rdd.flatMap(lambda x: x).collect())\n",
    "\n",
    "X_test = np.array(test_df.select(\"features\").rdd.flatMap(lambda x: x).collect())\n",
    "y_test = np.array(test_df.select(\"outcome\").rdd.flatMap(lambda x: x).collect())\n",
    "\n",
    "class MyDataSet(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "train_dataset = MyDataSet(X_train, y_train)\n",
    "val_dataset = MyDataSet(X_val, y_val)\n",
    "test_dataset = MyDataSet(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleLayerNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SingleLayerNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc1(x)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLayerNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(MultiLayerNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search for Single-Layer Model\n",
      "\n",
      "Training with lr=0.01, batch_size=32\n",
      "\n",
      "Training with lr=0.01, batch_size=64\n",
      "\n",
      "Training with lr=0.001, batch_size=32\n",
      "\n",
      "Training with lr=0.001, batch_size=64\n",
      "\n",
      "Best parameters found:\n",
      "{'lr': 0.01, 'batch_size': 64}\n",
      "Validation RMSE with best parameters: 2.5196\n",
      "\n",
      "Grid Search for Multi-Layer Model\n",
      "\n",
      "Training with lr=0.01, batch_size=32\n",
      "\n",
      "Training with lr=0.01, batch_size=64\n",
      "\n",
      "Training with lr=0.001, batch_size=32\n",
      "\n",
      "Training with lr=0.001, batch_size=64\n",
      "\n",
      "Best parameters found:\n",
      "{'lr': 0.01, 'batch_size': 64}\n",
      "Validation RMSE with best parameters: 0.8684\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "param_grid = {\n",
    "    'lr': [0.01, 0.001],\n",
    "    'batch_size': [32, 64]\n",
    "}\n",
    "\n",
    "def train_and_evaluate(model, train_loader, val_loader, lr=0.01, epochs=20):\n",
    "    criterion = nn.MSELoss() \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    best_val_rmse = float('inf')\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_train_loss = 0\n",
    "        for batch_features, batch_labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_features)\n",
    "            loss = criterion(outputs, batch_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_train_loss += loss.item()\n",
    "        \n",
    "        epoch_train_loss /= len(train_loader)\n",
    "        \n",
    "        model.eval()\n",
    "        epoch_val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for val_features, val_labels in val_loader:\n",
    "                val_outputs = model(val_features)\n",
    "                val_loss = criterion(val_outputs, val_labels)\n",
    "                epoch_val_loss += val_loss.item()\n",
    "        \n",
    "        epoch_val_loss /= len(val_loader)\n",
    "        val_rmse = np.sqrt(epoch_val_loss)\n",
    "\n",
    "        # Check if this is the best model so far\n",
    "        if val_rmse < best_val_rmse:\n",
    "            best_val_rmse = val_rmse\n",
    "            best_model_state = model.state_dict()  # Save the best model’s state\n",
    "\n",
    "    # Load the best model state for final evaluation\n",
    "    if best_model_state:\n",
    "        model.load_state_dict(best_model_state)\n",
    "    \n",
    "    return best_val_rmse\n",
    "\n",
    "def grid_search(model_class, param_grid, X_train, y_train, X_val, y_val, model_name = \"model\"):\n",
    "    best_rmse = float('inf')\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "\n",
    "    # Iterate over all parameter combinations\n",
    "    for lr, batch_size in itertools.product(param_grid['lr'], param_grid['batch_size']):\n",
    "        print(f\"\\nTraining with lr={lr}, batch_size={batch_size}\")\n",
    "\n",
    "        model = model_class(X_train.shape[1])\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "        # Train and evaluate on validation data\n",
    "        val_rmse = train_and_evaluate(model, train_loader, val_loader, lr=lr)\n",
    "\n",
    "        # Update best model if validation RMSE improves\n",
    "        if val_rmse < best_rmse:\n",
    "            best_rmse = val_rmse\n",
    "            best_params = {'lr': lr, 'batch_size': batch_size}\n",
    "            best_model = model\n",
    "            torch.save(best_model.state_dict(), f\"{model_name}_best_model.pth\")\n",
    "            \n",
    "    # Print best parameters\n",
    "    print(\"\\nBest parameters found:\")\n",
    "    print(best_params)\n",
    "    print(f\"Validation RMSE with best parameters: {best_rmse:.4f}\")\n",
    "    \n",
    "    return best_model, best_params\n",
    "\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "print(\"Grid Search for Single-Layer Model\")\n",
    "best_single_layer_model, best_single_params = grid_search(SingleLayerNN, param_grid, X_train, y_train, X_val, y_val, \"single_layer\")\n",
    "\n",
    "print(\"\\nGrid Search for Multi-Layer Model\")\n",
    "best_multi_layer_model, best_multi_params = grid_search(MultiLayerNN, param_grid, X_train, y_train, X_val, y_val, \"multi_layer\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\suyue\\AppData\\Local\\Temp\\ipykernel_12492\\828742228.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_single_layer_model.load_state_dict(torch.load(\"single_layer_best_model.pth\"))\n",
      "C:\\Users\\suyue\\AppData\\Local\\Temp\\ipykernel_12492\\828742228.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  best_multi_layer_model.load_state_dict(torch.load(\"multi_layer_best_model.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_single_layer_model = SingleLayerNN(input_dim)\n",
    "best_single_layer_model.load_state_dict(torch.load(\"single_layer_best_model.pth\"))\n",
    "\n",
    "best_multi_layer_model = MultiLayerNN(input_dim)\n",
    "best_multi_layer_model.load_state_dict(torch.load(\"multi_layer_best_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Single-Layer Model on Test Data\n",
      "Test RMSE: 2.5601\n",
      "\n",
      "Evaluating Multi-Layer Model on Test Data\n",
      "Test RMSE: 0.9134\n"
     ]
    }
   ],
   "source": [
    "def final_test_evaluation(model, test_loader):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    with torch.no_grad():\n",
    "        for batch_features, batch_labels in test_loader:\n",
    "            outputs = model(batch_features)\n",
    "            predictions.extend(outputs.numpy())\n",
    "            actuals.extend(batch_labels.numpy())\n",
    "    \n",
    "    test_mse = mean_squared_error(actuals, predictions)\n",
    "    test_rmse = np.sqrt(test_mse)\n",
    "    print(f\"Test RMSE: {test_rmse:.4f}\")\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=best_single_params['batch_size'], shuffle=False)\n",
    "print(\"\\nEvaluating Single-Layer Model on Test Data\")\n",
    "final_test_evaluation(best_single_layer_model, test_loader)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=best_multi_params['batch_size'], shuffle=False)\n",
    "print(\"\\nEvaluating Multi-Layer Model on Test Data\")\n",
    "final_test_evaluation(best_multi_layer_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
